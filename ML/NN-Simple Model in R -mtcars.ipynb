{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    " \n",
    "Today we will build a neural network (NN) from scratch. \n",
    "\n",
    "The structure of the NN is shown in the following image:\n",
    "  \n",
    "<img src=\"https://i1.wp.com/res.cloudinary.com/dxqnb8xjb/image/upload/v1539018324/nn_diagram_d7gs7e.png?w=456&ssl=1\" />\n",
    " \n",
    " \n",
    "This NN have three layers: \n",
    "\n",
    "- Input layer: this layer is constitute the input data\n",
    "- Hidden layer: this is the most internal layer. This layer is not visible to the user that is why NN are considered black boxes. \n",
    "- Output layer: this layer will contain our output ($\\hat{y}$)\n",
    "\n",
    "\n",
    "<img src=\"https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/Single-Perceptron.png?x31195\" width=\"600\" height=\"400\" />\n",
    " \n",
    " \n",
    "We proceed with the input layer and calculate the weights and the bias for each of the input (X's): transfer function\n",
    " \n",
    "$$ z = W_{i1}^{T}X + b_1 $$\n",
    "\n",
    "This is called the <b> Transfer Function </b>. After that, the resulting vector (z) is passed through an <b> Activation Function </b>. There are many types of activation functions, one of them we yet know, the <b>sigmoid function </b>:\n",
    " \n",
    "$$   \\sigma = 1 / (1 + exp^{-z})  $$\n",
    "\n",
    "Lets code this functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the activation function\n",
    "sigmoid <- function(x) {\n",
    "  1.0 / (1.0 + exp(-x))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward\n",
    " \n",
    "The transfer and activation functions are applyed to the first layer (input layer) and the resuts are passed to the following layer (hidden layer) and both functions are now applied to it. Then the reult is passed to the output layer. Those passes are known as feedforward step. Now we will define this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feedforward from input to output\n",
    "feedforward <- function(nn) {\n",
    "  ## activation of the first layer\n",
    "  nn$layer1 <- sigmoid(nn$input %*% nn$weights1)\n",
    "  ## activation of the following layer\n",
    "  nn$output <- sigmoid(nn$layer1 %*% nn$weights2)\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, the final feedforward function for our network looks as follows:\n",
    " \n",
    "$$ \\hat{y} = \\sigma(W_2^{T}(\\sigma(W_1^{T}X) + b_1) + b_2 )  $$\n",
    " \n",
    "\n",
    "## Backpropagation\n",
    " \n",
    "The resulting output of the feedforward step gives a result that has a high error (loss). To reduce this error, the weight and bias are corrected by going backwards. This step is known as backpropagation. This is done by the following function:\n",
    " \n",
    "$$  2(y - \\hat{y}) * z(1-z) * X $$\n",
    " \n",
    "where z is\n",
    "\n",
    "$$  z = (W^{T}X + b) $$\n",
    "\n",
    "and $ z(1-z) $ is known as the <b>derivative of the sigmoid function</b>.\n",
    "\n",
    "Now we add the code for the backpropagation function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the derivative of the activation function\n",
    "sigmoid_derivative <- function(x) {\n",
    "  return(x * (1.0 - x))\n",
    "}\n",
    "\n",
    "## Backpropagation\n",
    "backprop <- function(nn) {\n",
    "  # application of the chain rule to find derivative of the loss function with \n",
    "  # respect to weights2 and weights1\n",
    "    \n",
    "  # `2 * (nn$y - nn$output)` is the derivative of the sigmoid loss function\n",
    "  d_weights2 <- ( t(nn$layer1) %*% (2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) )\n",
    "\n",
    "  d_weights1 <- ( 2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) %*% t(nn$weights2)\n",
    "    \n",
    "  d_weights1 <- d_weights1 * sigmoid_derivative(nn$layer1)\n",
    "    \n",
    "  d_weights1 <- t(nn$input) %*% d_weights1\n",
    "  \n",
    "  # update the weights using the derivative (slope) of the loss function\n",
    "  nn$weights1 <- nn$weights1 + d_weights1\n",
    "  nn$weights2 <- nn$weights2 + d_weights2\n",
    "\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    " \n",
    "Now that we have all the needed functions for our NN, we have to define the loss function. We will use the Sum of Squared Error: \n",
    "\n",
    "$$  cost = \\sum_{i=1}^{n} {(y - \\hat{y})^{2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function: SSE\n",
    "loss_function <- function(nn) {\n",
    "  return(sum((nn$y - nn$output) ^ 2))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And  we define the gradient descent function by running the network (feed)fordward and backward (backpropagation) while recalculating the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD <- function(nnet, num_iter=100) {\n",
    "    n <- num_iter\n",
    "\n",
    "    # data frame to store the results of the loss function.\n",
    "    # this data frame is used to produce the plot in the \n",
    "    # next code chunk\n",
    "    loss_df <- data.frame(iteration = 1:n+1, loss = vector(\"numeric\", length = n) )\n",
    "\n",
    "    for (i in seq_len(num_iter)) {\n",
    "      nnet <- feedforward(nnet)\n",
    "      nnet <- backprop(nnet)\n",
    "\n",
    "      # store the result of the loss function.  We will plot this later\n",
    "      loss_df$loss[i] <- loss_function(nnet)\n",
    "    }\n",
    "    # print the predicted outcome next to the actual outcome\n",
    "    yhat <- data.frame(\"Predicted\" = round(nnet$output, 3), \"Actual\" = y)\n",
    "    res <- list(yhat=yhat, loss=loss_df)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NeuralNetwork <- function(X, y, num_nodes, num_iter=100) { #only 1 layer\n",
    "    # generate a random value between 0 and 1 for each\n",
    "    # element in X.  This will be used as our initial weights\n",
    "    # for layer 1\n",
    "    rand_vector <- runif(ncol(X) * nrow(X))\n",
    "\n",
    "    # convert above vector into a matrix\n",
    "    rand_matrix <- matrix(rand_vector, nrow = ncol(X), ncol = nrow(X), byrow = TRUE)\n",
    "\n",
    "    # this list stores the state of our neural net as it is trained\n",
    "    nnet <- list(input = X,                              # predictor variables\n",
    "                  weights1 = rand_matrix,                 # weights for layer 1\n",
    "                  weights2 = matrix(runif(num_nodes), ncol = 1),  # weights for layer 2\n",
    "                  y = y,                                  # actual observed\n",
    "                  output = matrix(rep(0, times = num_nodes), ncol = 1)   # stores the predicted outcome\n",
    "                 )\n",
    "    return(GD(nnet, num_iter))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Mazda RX4        </td><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.620</td><td>16.46</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>Mazda RX4 Wag    </td><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>Datsun 710       </td><td>22.8</td><td>4</td><td>108</td><td> 93</td><td>3.85</td><td>2.320</td><td>18.61</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>Hornet 4 Drive   </td><td>21.4</td><td>6</td><td>258</td><td>110</td><td>3.08</td><td>3.215</td><td>19.44</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>Hornet Sportabout</td><td>18.7</td><td>8</td><td>360</td><td>175</td><td>3.15</td><td>3.440</td><td>17.02</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>Valiant          </td><td>18.1</td><td>6</td><td>225</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 12\n",
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & X & mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb\\\\\n",
       "  & <fct> & <dbl> & <int> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & Mazda RX4         & 21.0 & 6 & 160 & 110 & 3.90 & 2.620 & 16.46 & 0 & 1 & 4 & 4\\\\\n",
       "\t2 & Mazda RX4 Wag     & 21.0 & 6 & 160 & 110 & 3.90 & 2.875 & 17.02 & 0 & 1 & 4 & 4\\\\\n",
       "\t3 & Datsun 710        & 22.8 & 4 & 108 &  93 & 3.85 & 2.320 & 18.61 & 1 & 1 & 4 & 1\\\\\n",
       "\t4 & Hornet 4 Drive    & 21.4 & 6 & 258 & 110 & 3.08 & 3.215 & 19.44 & 1 & 0 & 3 & 1\\\\\n",
       "\t5 & Hornet Sportabout & 18.7 & 8 & 360 & 175 & 3.15 & 3.440 & 17.02 & 0 & 0 & 3 & 2\\\\\n",
       "\t6 & Valiant           & 18.1 & 6 & 225 & 105 & 2.76 & 3.460 & 20.22 & 1 & 0 & 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 12\n",
       "\n",
       "| <!--/--> | X &lt;fct&gt; | mpg &lt;dbl&gt; | cyl &lt;int&gt; | disp &lt;dbl&gt; | hp &lt;int&gt; | drat &lt;dbl&gt; | wt &lt;dbl&gt; | qsec &lt;dbl&gt; | vs &lt;int&gt; | am &lt;int&gt; | gear &lt;int&gt; | carb &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | Mazda RX4         | 21.0 | 6 | 160 | 110 | 3.90 | 2.620 | 16.46 | 0 | 1 | 4 | 4 |\n",
       "| 2 | Mazda RX4 Wag     | 21.0 | 6 | 160 | 110 | 3.90 | 2.875 | 17.02 | 0 | 1 | 4 | 4 |\n",
       "| 3 | Datsun 710        | 22.8 | 4 | 108 |  93 | 3.85 | 2.320 | 18.61 | 1 | 1 | 4 | 1 |\n",
       "| 4 | Hornet 4 Drive    | 21.4 | 6 | 258 | 110 | 3.08 | 3.215 | 19.44 | 1 | 0 | 3 | 1 |\n",
       "| 5 | Hornet Sportabout | 18.7 | 8 | 360 | 175 | 3.15 | 3.440 | 17.02 | 0 | 0 | 3 | 2 |\n",
       "| 6 | Valiant           | 18.1 | 6 | 225 | 105 | 2.76 | 3.460 | 20.22 | 1 | 0 | 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  X                 mpg  cyl disp hp  drat wt    qsec  vs am gear carb\n",
       "1 Mazda RX4         21.0 6   160  110 3.90 2.620 16.46 0  1  4    4   \n",
       "2 Mazda RX4 Wag     21.0 6   160  110 3.90 2.875 17.02 0  1  4    4   \n",
       "3 Datsun 710        22.8 4   108   93 3.85 2.320 18.61 1  1  4    1   \n",
       "4 Hornet 4 Drive    21.4 6   258  110 3.08 3.215 19.44 1  0  3    1   \n",
       "5 Hornet Sportabout 18.7 8   360  175 3.15 3.440 17.02 0  0  3    2   \n",
       "6 Valiant           18.1 6   225  105 2.76 3.460 20.22 1  0  3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, we create the data to train the neural network.\n",
    "df <- read.csv(file = \"C:/Users/Mayer/Documents/DataScience/data/mtcars.csv\")\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 11 of type chr</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X</th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>gear</th><th scope=col>carb</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Mazda RX4        </td><td>21.0</td><td>6</td><td>160.0</td><td>110</td><td>3.90</td><td>2.620</td><td>16.46</td><td>0</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><td>Mazda RX4 Wag    </td><td>21.0</td><td>6</td><td>160.0</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><td>Datsun 710       </td><td>22.8</td><td>4</td><td>108.0</td><td> 93</td><td>3.85</td><td>2.320</td><td>18.61</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "\t<tr><td>Hornet 4 Drive   </td><td>21.4</td><td>6</td><td>258.0</td><td>110</td><td>3.08</td><td>3.215</td><td>19.44</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><td>Hornet Sportabout</td><td>18.7</td><td>8</td><td>360.0</td><td>175</td><td>3.15</td><td>3.440</td><td>17.02</td><td>0</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><td>Valiant          </td><td>18.1</td><td>6</td><td>225.0</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 11 of type chr\n",
       "\\begin{tabular}{lllllllllll}\n",
       " X & mpg & cyl & disp & hp & drat & wt & qsec & vs & gear & carb\\\\\n",
       "\\hline\n",
       "\t Mazda RX4         & 21.0 & 6 & 160.0 & 110 & 3.90 & 2.620 & 16.46 & 0 & 4 & 4\\\\\n",
       "\t Mazda RX4 Wag     & 21.0 & 6 & 160.0 & 110 & 3.90 & 2.875 & 17.02 & 0 & 4 & 4\\\\\n",
       "\t Datsun 710        & 22.8 & 4 & 108.0 &  93 & 3.85 & 2.320 & 18.61 & 1 & 4 & 1\\\\\n",
       "\t Hornet 4 Drive    & 21.4 & 6 & 258.0 & 110 & 3.08 & 3.215 & 19.44 & 1 & 3 & 1\\\\\n",
       "\t Hornet Sportabout & 18.7 & 8 & 360.0 & 175 & 3.15 & 3.440 & 17.02 & 0 & 3 & 2\\\\\n",
       "\t Valiant           & 18.1 & 6 & 225.0 & 105 & 2.76 & 3.460 & 20.22 & 1 & 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 11 of type chr\n",
       "\n",
       "| X | mpg | cyl | disp | hp | drat | wt | qsec | vs | gear | carb |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Mazda RX4         | 21.0 | 6 | 160.0 | 110 | 3.90 | 2.620 | 16.46 | 0 | 4 | 4 |\n",
       "| Mazda RX4 Wag     | 21.0 | 6 | 160.0 | 110 | 3.90 | 2.875 | 17.02 | 0 | 4 | 4 |\n",
       "| Datsun 710        | 22.8 | 4 | 108.0 |  93 | 3.85 | 2.320 | 18.61 | 1 | 4 | 1 |\n",
       "| Hornet 4 Drive    | 21.4 | 6 | 258.0 | 110 | 3.08 | 3.215 | 19.44 | 1 | 3 | 1 |\n",
       "| Hornet Sportabout | 18.7 | 8 | 360.0 | 175 | 3.15 | 3.440 | 17.02 | 0 | 3 | 2 |\n",
       "| Valiant           | 18.1 | 6 | 225.0 | 105 | 2.76 | 3.460 | 20.22 | 1 | 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     X                 mpg  cyl disp  hp  drat wt    qsec  vs gear carb\n",
       "[1,] Mazda RX4         21.0 6   160.0 110 3.90 2.620 16.46 0  4    4   \n",
       "[2,] Mazda RX4 Wag     21.0 6   160.0 110 3.90 2.875 17.02 0  4    4   \n",
       "[3,] Datsun 710        22.8 4   108.0  93 3.85 2.320 18.61 1  4    1   \n",
       "[4,] Hornet 4 Drive    21.4 6   258.0 110 3.08 3.215 19.44 1  3    1   \n",
       "[5,] Hornet Sportabout 18.7 8   360.0 175 3.15 3.440 17.02 0  3    2   \n",
       "[6,] Valiant           18.1 6   225.0 105 2.76 3.460 20.22 1  3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# predictor variables\n",
    "X <- as.matrix(df[,-10])\n",
    "head(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 1 of type int</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>am</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>1</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 1 of type int\n",
       "\\begin{tabular}{l}\n",
       " am\\\\\n",
       "\\hline\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 1\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 1 of type int\n",
       "\n",
       "| am |\n",
       "|---|\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 1 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "     am\n",
       "[1,] 1 \n",
       "[2,] 1 \n",
       "[3,] 1 \n",
       "[4,] 0 \n",
       "[5,] 0 \n",
       "[6,] 0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# observed outcomes\n",
    "y <- as.matrix(df[10])\n",
    "head(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t32 obs. of  12 variables:\n",
      " $ X   : Factor w/ 32 levels \"AMC Javelin\",..: 18 19 5 13 14 31 7 21 20 22 ...\n",
      " $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n",
      " $ cyl : int  6 6 4 6 8 6 8 4 4 6 ...\n",
      " $ disp: num  160 160 108 258 360 ...\n",
      " $ hp  : int  110 110 93 110 175 105 245 62 95 123 ...\n",
      " $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n",
      " $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n",
      " $ qsec: num  16.5 17 18.6 19.4 17 ...\n",
      " $ vs  : int  0 0 1 1 0 1 0 1 1 1 ...\n",
      " $ am  : int  1 1 1 0 0 0 0 0 0 0 ...\n",
      " $ gear: int  4 4 4 3 3 3 3 4 4 4 ...\n",
      " $ carb: int  4 4 1 1 2 1 4 2 2 4 ...\n"
     ]
    }
   ],
   "source": [
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nn$input %*% nn$weights1: requires numeric/complex matrix/vector arguments\n",
     "output_type": "error",
     "traceback": [
      "Error in nn$input %*% nn$weights1: requires numeric/complex matrix/vector arguments\nTraceback:\n",
      "1. NeuralNetwork(X, y, num_nodes = 4, num_iter = 1000)",
      "2. GD(nnet, num_iter)   # at line 18 of file <text>",
      "3. feedforward(nnet)   # at line 10 of file <text>",
      "4. sigmoid(nn$input %*% nn$weights1)   # at line 4 of file <text>"
     ]
    }
   ],
   "source": [
    "nn <- NeuralNetwork(X,y,num_nodes=4, num_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 4 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Predicted</th><th scope=col>Actual</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.025</td><td>0</td></tr>\n",
       "\t<tr><td>0.979</td><td>1</td></tr>\n",
       "\t<tr><td>0.966</td><td>1</td></tr>\n",
       "\t<tr><td>0.031</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 2\n",
       "\\begin{tabular}{ll}\n",
       " Predicted & Actual\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.025 & 0\\\\\n",
       "\t 0.979 & 1\\\\\n",
       "\t 0.966 & 1\\\\\n",
       "\t 0.031 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 2\n",
       "\n",
       "| Predicted &lt;dbl&gt; | Actual &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 0.025 | 0 |\n",
       "| 0.979 | 1 |\n",
       "| 0.966 | 1 |\n",
       "| 0.031 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Predicted Actual\n",
       "1 0.025     0     \n",
       "2 0.979     1     \n",
       "3 0.966     1     \n",
       "4 0.031     0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>2</td><td>1.518857</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>3</td><td>1.247433</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>4</td><td>1.025016</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>5</td><td>1.000515</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>6</td><td>1.000378</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>7</td><td>1.000243</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & iteration & loss\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 2 & 1.518857\\\\\n",
       "\t2 & 3 & 1.247433\\\\\n",
       "\t3 & 4 & 1.025016\\\\\n",
       "\t4 & 5 & 1.000515\\\\\n",
       "\t5 & 6 & 1.000378\\\\\n",
       "\t6 & 7 & 1.000243\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 2 | 1.518857 |\n",
       "| 2 | 3 | 1.247433 |\n",
       "| 3 | 4 | 1.025016 |\n",
       "| 4 | 5 | 1.000515 |\n",
       "| 5 | 6 | 1.000378 |\n",
       "| 6 | 7 | 1.000243 |\n",
       "\n"
      ],
      "text/plain": [
       "  iteration loss    \n",
       "1 2         1.518857\n",
       "2 3         1.247433\n",
       "3 4         1.025016\n",
       "4 5         1.000515\n",
       "5 6         1.000378\n",
       "6 7         1.000243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>995</th><td> 996</td><td>0.003227988</td></tr>\n",
       "\t<tr><th scope=row>996</th><td> 997</td><td>0.003223035</td></tr>\n",
       "\t<tr><th scope=row>997</th><td> 998</td><td>0.003218096</td></tr>\n",
       "\t<tr><th scope=row>998</th><td> 999</td><td>0.003213171</td></tr>\n",
       "\t<tr><th scope=row>999</th><td>1000</td><td>0.003208261</td></tr>\n",
       "\t<tr><th scope=row>1000</th><td>1001</td><td>0.003203365</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & iteration & loss\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t995 &  996 & 0.003227988\\\\\n",
       "\t996 &  997 & 0.003223035\\\\\n",
       "\t997 &  998 & 0.003218096\\\\\n",
       "\t998 &  999 & 0.003213171\\\\\n",
       "\t999 & 1000 & 0.003208261\\\\\n",
       "\t1000 & 1001 & 0.003203365\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 995 |  996 | 0.003227988 |\n",
       "| 996 |  997 | 0.003223035 |\n",
       "| 997 |  998 | 0.003218096 |\n",
       "| 998 |  999 | 0.003213171 |\n",
       "| 999 | 1000 | 0.003208261 |\n",
       "| 1000 | 1001 | 0.003203365 |\n",
       "\n"
      ],
      "text/plain": [
       "     iteration loss       \n",
       "995   996      0.003227988\n",
       "996   997      0.003223035\n",
       "997   998      0.003218096\n",
       "998   999      0.003213171\n",
       "999  1000      0.003208261\n",
       "1000 1001      0.003203365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn$yhat # the probability to get 1\n",
    "head(nn$loss)\n",
    "tail(nn$loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAABmJLR0QA/wD/AP+gvaeTAAAg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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 240,
       "width": 240
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 4, repr.plot.height = 4)\n",
    "\n",
    "# plot the cost\n",
    "library(ggplot2)\n",
    "\n",
    "ggplot(data = nn$loss, aes(x = iteration, y = loss)) +\n",
    "  geom_line()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
